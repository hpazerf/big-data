{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tbfz3zSXBt3H"
   },
   "source": [
    "In this Project, we will work with CIFAR10 image dataset. \n",
    "The starter code to download the database using keras is given below. \n",
    "Test the project on Google Colab running on a CPU, GPU and TPU\n",
    " \n",
    "\n",
    "# In every line of code, please write a comment to briefly explain what that line is doing.\n",
    "Your grades will be based on your understanding of the code you write! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBDorl_8scVn"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnHTzAuvxxQT"
   },
   "source": [
    "# Task 1\n",
    "Convert the features in a form that can be given as input to tensorflow library/functions\n",
    "\n",
    "In this task you will perform data augmentation. That is, pre-process the data to make the model more robust. Experiment with common data augmentation techniques like rotation, translation, horizontal-flips, scaling and histogram equalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "fWKWhGjZseXc",
    "outputId": "73bef426-9574-4279-ce8c-d2b86c16dc3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "# downloading and separating the data into a training and test set.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnZZCE-by-zY"
   },
   "outputs": [],
   "source": [
    "# Creatingt the augmentation tool\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6c8xzloyoUD"
   },
   "source": [
    "# Task 2\n",
    "Build a Deep Learning Neural Network model, train on the features and report the accuracy.\n",
    "Report your observations on the time taken on a CPU and GPU (with and without CuDNN kernel).  \n",
    "\n",
    "\n",
    "1.   Create a CNN based model with 4 hidden layers with 64, 128, 256, 512 units in each successive layer. \n",
    "2.   Create an LSTM based model with 1 LSTM layer with 256  units. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUFd_grAuzlO"
   },
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_vpGRXntQdR"
   },
   "outputs": [],
   "source": [
    "# Creating a function to create a CNN based model with 4 hidden layers and 4, 128, 256, 512 units in each successive layer\n",
    "def create_model():\n",
    "  # Sequential Model\n",
    "  model = tf.keras.models.Sequential()\n",
    "  # First Layer\n",
    "  # Normalizing the inputs\n",
    "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
    "  # Creating 64 channels using a 5 x 5 matrix.\n",
    "  model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
    "  # Max pooling with a 2x2 matrix\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  # Drop random nodes\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "  \n",
    "  # Second Layer\n",
    "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
    "  model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "  #Third Layer\n",
    "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
    "  model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "  # Fourth Layer\n",
    "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
    "  model.add(tf.keras.layers.Conv2D(512, (5, 5), padding='same', activation='elu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "  # Flattening the Dataset\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  \n",
    "  model.add(tf.keras.layers.Dense(256))\n",
    "  model.add(tf.keras.layers.Activation('elu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(10))\n",
    "  model.add(tf.keras.layers.Activation('softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ubg9ZuQZu_EP"
   },
   "source": [
    "### Running on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "sf1iOztct31f",
    "outputId": "7c3c301e-24aa-422b-ce85-06493ffc9c3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 304 ms, sys: 4.05 ms, total: 308 ms\n",
      "Wall time: 277 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = create_model()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "CCcJwxvwt58v",
    "outputId": "077a2970-0dfe-4cb1-b6aa-5ba2a4ca5f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 451s 902ms/step - loss: 2.5558 - sparse_categorical_accuracy: 0.2221\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 452s 903ms/step - loss: 2.0370 - sparse_categorical_accuracy: 0.2774\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 453s 905ms/step - loss: 1.8196 - sparse_categorical_accuracy: 0.3290\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 451s 902ms/step - loss: 1.6739 - sparse_categorical_accuracy: 0.3787\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 449s 899ms/step - loss: 1.5490 - sparse_categorical_accuracy: 0.4419\n",
      "CPU times: user 1h 12min 13s, sys: 49.6 s, total: 1h 13min 3s\n",
      "Wall time: 37min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff470da6828>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(\n",
    "    datagen.flow(x_train.astype(np.float32), y_train.astype(np.float32)),\n",
    "    epochs=5,\n",
    "    batch_size =50,\n",
    "    steps_per_epoch=500,\n",
    "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
    "    validation_freq=17\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "4TEG93epuo0B",
    "outputId": "a18cca0d-b9e4-4591-e78c-c7cd9e492f38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 58s 186ms/step - loss: 1.3002 - sparse_categorical_accuracy: 0.5162\n",
      "Test loss: 1.3001537322998047\n",
      "Test accuracy: 0.5162000060081482\n",
      "CPU times: user 1min 49s, sys: 665 ms, total: 1min 50s\n",
      "Wall time: 58.6 s\n"
     ]
    }
   ],
   "source": [
    "# Print out the accuracy of the model on the test set\n",
    "%%time\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rw-JhSiIvEYl"
   },
   "source": [
    "### Running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "KoJ6KbvtvEYm",
    "outputId": "05f7da03-579d-4741-be4e-1168e3bc198b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 187 ms, sys: 6.55 ms, total: 193 ms\n",
      "Wall time: 194 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = create_model()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "Yqyj_chJvEYo",
    "outputId": "394395a3-4c26-48b1-e37b-d61ff50b41c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 1.8291 - sparse_categorical_accuracy: 0.3307\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 1.6752 - sparse_categorical_accuracy: 0.3814\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 1.5718 - sparse_categorical_accuracy: 0.4360\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 1.4688 - sparse_categorical_accuracy: 0.4759\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 1.3813 - sparse_categorical_accuracy: 0.5168\n",
      "CPU times: user 1min 5s, sys: 7.18 s, total: 1min 12s\n",
      "Wall time: 48.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f38e8205cf8>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(\n",
    "    datagen.flow(x_train.astype(np.float32), y_train.astype(np.float32)),\n",
    "    epochs=5,\n",
    "    batch_size =50,\n",
    "    steps_per_epoch=500,\n",
    "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
    "    validation_freq=17\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "Mho53Qe5vEYq",
    "outputId": "42cd7e0f-72ce-4604-b1a3-485db3c3b058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 1.1736 - sparse_categorical_accuracy: 0.5871\n",
      "Test loss: 1.1735551357269287\n",
      "Test accuracy: 0.5871000289916992\n",
      "CPU times: user 1.2 s, sys: 123 ms, total: 1.32 s\n",
      "Wall time: 1.92 s\n"
     ]
    }
   ],
   "source": [
    "# Print out the accuracy of the model on the test set\n",
    "%%time\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uoH946Cu34_"
   },
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_VSrNeE_Yfo"
   },
   "outputs": [],
   "source": [
    "# batchs\n",
    "batch_size = 50\n",
    "# Each MNIST image batch is a tensor of shape (batch_size, 32, 32).\n",
    "# Each input sequence will be of size (32, 32) (height is treated like time).\n",
    "input_dim = 32   # Features\n",
    "\n",
    "units = 256\n",
    "output_size = 10  # labels are from 0 to 9\n",
    "\n",
    "# Build the RNN model\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "  # CuDNN is only available at the layer level, and not at the cell level.\n",
    "  # This means `LSTM(units)` will use the CuDNN kernel,\n",
    "  # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
    "  if allow_cudnn_kernel:\n",
    "    # The LSTM layer with default options uses CuDNN.\n",
    "    lstm_layer = tf.keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
    "  else:\n",
    "    # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
    "    lstm_layer = tf.keras.layers.RNN(\n",
    "        tf.keras.layers.LSTMCell(units),\n",
    "        input_shape=(None, input_dim))\n",
    "  model = tf.keras.models.Sequential([\n",
    "      lstm_layer,\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dense(output_size, activation='softmax')]\n",
    "  )\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLJIP-fN3ICq"
   },
   "source": [
    "### Transformations\n",
    "The reason we applied the transforms and then added it to the image list due to the fact the the flow method expected 4 ndim and the LSMT model expected 3 ndim. Due to this conflict we were unable to figure out a way to implement the flow method while running the LSTM model. Our solution was to apply transformations before putting it in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3O6xDezI3Hel"
   },
   "outputs": [],
   "source": [
    "# Create data generator object\n",
    "datagen = ImageDataGenerator()\n",
    "# Loop through each image, horizontal flip the image, and add to new list of images\n",
    "x_train_transform = []\n",
    "for i in range(len(x_train)):\n",
    "  x_train_image = datagen.apply_transform(x_train[i], {'flip_horizontal':True, 'theta': 40})\n",
    "  x_train_transform.append(x_train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exi-ayKG3rwR",
    "outputId": "f5b0ea6b-f9bd-4252-92a6-efb2b584fb60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining original images with flipped images\n",
    "new_x_train = np.append(x_train, x_train_transform, axis = 0)\n",
    "new_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uPZjszrc3uLp",
    "outputId": "0f0dc68f-cd7b-49cd-ba9d-fbd07a511910"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double the y values too\n",
    "new_y_train = np.append(y_train, y_train, axis = 0)\n",
    "new_y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqtRFGci3MLJ"
   },
   "source": [
    "### Changing to 3 images for each RGB value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qip2YpcXZMl8"
   },
   "outputs": [],
   "source": [
    "# Training Set\n",
    "# Separating the rgb values into three different images as the red, green, and blue image\n",
    "# Flattening the images to process\n",
    "x_train_rgblist=[]\n",
    "y_train_rgblist=[]\n",
    "# Recreating the image into the three different images\n",
    "for i in range(len(new_x_train)):\n",
    "  im_r = new_x_train[i,:,:,0]\n",
    "  im_g = new_x_train[i,:,:,1]\n",
    "  im_b = new_x_train[i,:,:,2]\n",
    "  x_train_rgblist.append(im_r)\n",
    "  x_train_rgblist.append(im_g)\n",
    "  x_train_rgblist.append(im_b)\n",
    "  y_train_rgblist.append(new_y_train[i])\n",
    "  y_train_rgblist.append(new_y_train[i])\n",
    "  y_train_rgblist.append(new_y_train[i])\n",
    "x_train_rgb=np.asarray(x_train_rgblist)\n",
    "y_train_rgb=np.asarray(y_train_rgblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xiPdzOYZOau"
   },
   "outputs": [],
   "source": [
    "# Testing Set\n",
    "# Separating the rgb values into three different images as the red, green, and blue image\n",
    "# Flattening the images to process\n",
    "x_test_rgblist=[]\n",
    "y_test_rgblist=[]\n",
    "# Recreating the image into the three different images\n",
    "for i in range(len(x_test)):\n",
    "  im_r = x_test[i,:,:,0]\n",
    "  im_g = x_test[i,:,:,1]\n",
    "  im_b = x_test[i,:,:,2]\n",
    "  x_test_rgblist.append(im_r)\n",
    "  x_test_rgblist.append(im_g)\n",
    "  x_test_rgblist.append(im_b)\n",
    "  y_test_rgblist.append(y_train[i])\n",
    "  y_test_rgblist.append(y_train[i])\n",
    "  y_test_rgblist.append(y_train[i])\n",
    "x_test_rgb=np.asarray(x_test_rgblist)\n",
    "y_test_rgb=np.asarray(y_test_rgblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UFAkbCGG-Nek",
    "outputId": "b831080b-98df-4d51-c781-cf33583687fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 32, 32)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_rgb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UB0ziW2Z_RKh"
   },
   "source": [
    "### Running on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "CVWmQsGzGWO-",
    "outputId": "27af9ac5-3205-48fd-b93e-96029300661c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 2.3632 - accuracy: 0.1199 - val_loss: 2.4066 - val_accuracy: 0.1011\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 84s 168ms/step - loss: 2.3141 - accuracy: 0.1236 - val_loss: 2.5094 - val_accuracy: 0.0991\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 85s 170ms/step - loss: 2.2971 - accuracy: 0.1257 - val_loss: 2.4140 - val_accuracy: 0.0986\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 2.2919 - accuracy: 0.1349 - val_loss: 2.4377 - val_accuracy: 0.0964\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 84s 167ms/step - loss: 2.2871 - accuracy: 0.1361 - val_loss: 2.3778 - val_accuracy: 0.0999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5e860f5828>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_model = build_model(allow_cudnn_kernel=False)\n",
    "\n",
    "slow_model.compile(loss='sparse_categorical_crossentropy', \n",
    "                   optimizer='sgd', \n",
    "                   metrics=['accuracy'])\n",
    "slow_model.fit(x_train_rgb, y_train_rgb,\n",
    "          validation_data=(x_test_rgb, y_test_rgb),\n",
    "          batch_size=batch_size,\n",
    "          steps_per_epoch=500,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "BK_a_YnFgpF3",
    "outputId": "eb8497b8-a943-426b-a99f-61da691ea514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 30s 32ms/step - loss: 2.3778 - accuracy: 0.0999\n",
      "Test loss: 2.3778388500213623\n",
      "Test accuracy: 0.09989999979734421\n",
      "CPU times: user 43.2 s, sys: 2.81 s, total: 46 s\n",
      "Wall time: 30.7 s\n"
     ]
    }
   ],
   "source": [
    "# Print out the accuracy of the model on the test set\n",
    "%%time\n",
    "scores = slow_model.evaluate(x_test_rgb, y_test_rgb)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4qYjXeq_VS_"
   },
   "source": [
    "### Running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "pAVAyVGrW0XF",
    "outputId": "36d4d636-3ad0-43d5-f3e5-9a1a73ae8c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/500 [..............................] - ETA: 5s - loss: 2.8058 - accuracy: 0.0840WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0085s vs `on_train_batch_end` time: 0.0145s). Check your callbacks.\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 2.2856 - accuracy: 0.1893 - val_loss: 2.5872 - val_accuracy: 0.1015\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.1561 - accuracy: 0.2209 - val_loss: 2.5966 - val_accuracy: 0.0962\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 2.1071 - accuracy: 0.2384 - val_loss: 2.5677 - val_accuracy: 0.0962\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 2.0797 - accuracy: 0.2484 - val_loss: 2.6352 - val_accuracy: 0.1005\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 2.0701 - accuracy: 0.2518 - val_loss: 2.5902 - val_accuracy: 0.0946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc07767eac8>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(allow_cudnn_kernel=True)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train_rgb, y_train_rgb,\n",
    "          validation_data=(x_test_rgb, y_test_rgb),\n",
    "          batch_size=batch_size,\n",
    "          steps_per_epoch=500,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "Rnn8NbtkW_hm",
    "outputId": "ac78b72c-dc6b-46c3-da5a-205c96fc1c19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 2.5902 - accuracy: 0.0946\n",
      "Test loss: 2.590157985687256\n",
      "Test accuracy: 0.09456666558980942\n",
      "CPU times: user 3.63 s, sys: 322 ms, total: 3.95 s\n",
      "Wall time: 3.46 s\n"
     ]
    }
   ],
   "source": [
    "# Print out the accuracy of the model on the test set\n",
    "%%time\n",
    "scores = model.evaluate(x_test_rgb, y_test_rgb)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsE9N2WefgnI"
   },
   "source": [
    "# Task 3\n",
    "(Bonus - you will have to do this by yourself)\n",
    "Run the LSTM solution on a TPU and report performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9t4xoOSQJhM0"
   },
   "source": [
    "We were able to connect to the TPU and get a faster result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "SvX3Ef0VFDjm",
    "outputId": "b1fcbbb8-9e26-4564-d113-6ea5a952c3da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.26.54.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.26.54.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.26.54.10:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.26.54.10:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.tpu.topology.Topology at 0x7f1c90e9be48>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#Get a handle to the attached TPU. On GCP it will be the CloudTPU itself\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "\n",
    "#Connect to the TPU handle and initialise it\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "qD_gY5fHFR0D",
    "outputId": "8f0fa13d-8f82-4230-f85f-d41594c6de96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5aHwgp6sFTMz"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  model = build_model(allow_cudnn_kernel=False)\n",
    "\n",
    "  model.compile(loss='sparse_categorical_crossentropy', \n",
    "                optimizer='sgd',\n",
    "                metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "1PlsWNtZuyJu",
    "outputId": "598e93fc-c03f-4dd0-e13e-3f36beb1c1b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 2.3517 - accuracy: 0.1372 - val_loss: 2.5735 - val_accuracy: 0.1004\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 2.2827 - accuracy: 0.1473 - val_loss: 2.6202 - val_accuracy: 0.0975\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 2.2641 - accuracy: 0.1494 - val_loss: 2.4399 - val_accuracy: 0.0965\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 2.2533 - accuracy: 0.1593 - val_loss: 2.3793 - val_accuracy: 0.1013\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 2.2653 - accuracy: 0.1424 - val_loss: 2.3975 - val_accuracy: 0.0973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc0d017ddd8>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_rgb.astype(np.float32), y_train_rgb.astype(np.float32),\n",
    "          validation_data=(x_test_rgb.astype(np.float32), y_test_rgb.astype(np.float32)),\n",
    "          batch_size=batch_size,\n",
    "          steps_per_epoch=500,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "LNc3Z2H5BPV_",
    "outputId": "f0db25a5-af52-4788-a9e7-27f6e060c276"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 2.3975 - accuracy: 0.0973\n",
      "Test loss: 2.3974902629852295\n",
      "Test accuracy: 0.09726666659116745\n",
      "CPU times: user 3.54 s, sys: 286 ms, total: 3.82 s\n",
      "Wall time: 3.27 s\n"
     ]
    }
   ],
   "source": [
    "# Print out the accuracy of the model on the test set\n",
    "%%time\n",
    "scores = model.evaluate(x_test_rgb.astype(np.float32), y_test_rgb.astype(np.float32))\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "iUFd_grAuzlO",
    "rw-JhSiIvEYl",
    "rLJIP-fN3ICq",
    "oqtRFGci3MLJ",
    "UB0ziW2Z_RKh"
   ],
   "name": "Project3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
